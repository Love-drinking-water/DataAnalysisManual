{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关联"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关联规则：反应一个事物与其他事物之间的相互依存性和关联性  案例：沃尔玛中啤酒与尿布\n",
    "    # 项目：一个字段，对交易来说一般是指一次交易中的一个物品，如：尿布\n",
    "    # 事务：某客户在一次交易中，发生的所有项目的集合：如{尿布，啤酒}\n",
    "    # 项集：包含若干个项集的集合（一次事务中）\n",
    "    # 频繁项集：某个项集的支持度大于设定的阈值（人为设定或值根据数据分布和经验来设定），即称这个项集为频繁项集\n",
    "        # 支持度：项集{X, Y}在总项集中出项的概率（Support）\n",
    "        # 置信度：在先决条件X发生的条件下，由关联规则{X->Y}推出Y的概率（Confidence）\n",
    "        # 提升度：表示含有X的条件下同时含有Y的概率，与无论含不含X,只要含有Y的概率之比（Confidence({X}->{Y})/Support({Y})） 置信度>1,表明X对Y有提升作用\n",
    "    # 常用算法：\n",
    "        # Apriori:先指定一个支持度的阈值，如果一个项集的支持度大于等于这个阈值，那么就认为是频繁项集，如果小于则不是。两个频繁项集组合在一起，可以是一个频繁项集，也可能不是。来两个非频繁相项集或一频繁一不频繁组合在一起一定不是一个频繁项集。\n",
    "# 序列规则：将时间的因素考虑进来，剔除关联规则中时间点靠后的项对时间点靠前的项的支持\n",
    "    # 算法\n",
    "        # Apriori-All\n",
    "            # 1.Forward:Apriori\n",
    "            # 2.Backward:去掉时间序列之后的项对之前的项的支持\n",
    "    # 使用场景：例如预测一个用户在购买了某产品之后，下次购物还会购买其他的什么东西作为搭配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "# 通过combinations 获取所有项集组合 包括1、2、3、4...项集\n",
    "def comb(lst):\n",
    "    ret=[]\n",
    "    # i 项集中项目的个数\n",
    "    for i in range(1,len(lst)+1):\n",
    "        ret+=list(combinations(lst,i))\n",
    "    return ret\n",
    "# 项目数量相同的项集集合\n",
    "class AprLayer(object):\n",
    "    d=dict()\n",
    "    def __init__(self):\n",
    "        self.d=dict()\n",
    "# AprNode 项集 \n",
    "class AprNode(object):\n",
    "    def __init__(self,node):\n",
    "        self.s=set(node)\n",
    "        # 项集的数量\n",
    "        self.size=len(self.s)\n",
    "        self.lnk_nodes=dict()\n",
    "        self.num=0\n",
    "    # 映射的方式：将项集中的所有项目进行排序，然后用__将其连接起来，建立一个hash索引\n",
    "    def __hash__(self):\n",
    "        return hash(\"__\".join(sorted([str(itm) for itm in list(self.s)])))\n",
    "    # 比较\n",
    "    def __eq__(self, other):\n",
    "        if \"__\".join(sorted([str(itm) for itm in list(self.s)]))==\"__\".join(sorted([str(itm) for itm in list(other.s)])):\n",
    "            return True\n",
    "        return False\n",
    "    def isSubnode(self,node):\n",
    "        return self.s.issubset(node.s)\n",
    "    # 加 1\n",
    "    def incNum(self,num=1):\n",
    "        self.num+=num\n",
    "    \n",
    "    # 加 node\n",
    "    def addLnk(self,node):\n",
    "        self.lnk_nodes[node]=node.s\n",
    "# 所有项集组成的集合体\n",
    "class AprBlk():\n",
    "    def __init__(self,data):\n",
    "        cnt=0\n",
    "        self.apr_layers = dict()\n",
    "        # 数据的长度\n",
    "        self.data_num=len(data)\n",
    "        for datum in data:\n",
    "            # 计数器\n",
    "            cnt+=1\n",
    "            # 获取项集\n",
    "            datum=comb(datum)\n",
    "            # da 项集的组合\n",
    "            nodes=[AprNode(da) for da in datum]\n",
    "            for node in nodes:\n",
    "                # 根据项集的数量建立相同的项集集合，（1，2，3...项集）\n",
    "                if not node.size in self.apr_layers:\n",
    "                    self.apr_layers[node.size]=AprLayer()\n",
    "                # 如果没有就直接加入\n",
    "                if not node in self.apr_layers[node.size].d:\n",
    "                    self.apr_layers[node.size].d[node]=node\n",
    "                # 将node数量加1\n",
    "                self.apr_layers[node.size].d[node].incNum()\n",
    "            # 建立低价与高阶之间的联系\n",
    "            for node in nodes:\n",
    "                if node.size==1:\n",
    "                    continue\n",
    "                for sn in node.s:\n",
    "                    sub_n=AprNode(node.s-set([sn]))\n",
    "                    # addLnk 建立联系\n",
    "                    self.apr_layers[node.size-1].d[sub_n].addLnk(node)\n",
    "    # 获取频繁项集 thd 阈值\n",
    "    def getFreqItems(self,thd=1,hd=1):\n",
    "        freq_items=[]\n",
    "        # 先遍历layer\n",
    "        for layer in self.apr_layers:\n",
    "            for node in self.apr_layers[layer].d:\n",
    "                # 判断数量是否小于阈值，是的话跳出本次循环\n",
    "                if self.apr_layers[layer].d[node].num<thd:\n",
    "                    continue\n",
    "                # 如果大于则加入项集   （频繁项集本身的node, node中项集一共出现的次数）\n",
    "                freq_items.append((self.apr_layers[layer].d[node].s,self.apr_layers[layer].d[node].num))\n",
    "        # 排序的依据是项集的次数，顺序从高到d\n",
    "        freq_items.sort(key=lambda x:x[1], reverse = True)\n",
    "        return freq_items[:hd]\n",
    "    # 置信度\n",
    "    # h_thd 高阈值\n",
    "    # l_thd 底阈值\n",
    "    def getConf(self,low=True, h_thd=10, l_thd=1, hd=1):\n",
    "        confidence = []\n",
    "        # 项集集合\n",
    "        for layer in self.apr_layers:\n",
    "            for node in self.apr_layers[layer].d:\n",
    "                if self.apr_layers[layer].d[node].num < h_thd:\n",
    "                    continue\n",
    "                for lnk_node in node.lnk_nodes:\n",
    "                    if lnk_node.num < l_thd:\n",
    "                        continue\n",
    "                    # 置信度    高阶频繁项集的数量/低阶频繁项集的数量\n",
    "                    conf = float(lnk_node.num) / float(node.num)\n",
    "                    # 输出             [项集，数量，连接，连接数量，置信度]\n",
    "                    confidence.append([node.s, node.num, lnk_node.s, lnk_node.num, conf])\n",
    "        # 根据置信度进行排序\n",
    "        confidence.sort(key=lambda x: x[4])\n",
    "        if low:\n",
    "            return confidence[:hd]\n",
    "        else:\n",
    "            return confidence[-hd::-1]\n",
    "# 关联规则的类\n",
    "class AssctAnaClass():\n",
    "    def fit(self,data):\n",
    "        # 建立集合体\n",
    "        self.apr_blk=AprBlk(data)\n",
    "        return self\n",
    "    # 获取频繁项集\n",
    "    # thd 阈值的数量 \n",
    "    # hd 取出前几个\n",
    "    def get_freq(self,thd=1,hd=1):\n",
    "        return self.apr_blk.getFreqItems(thd=thd,hd=hd)\n",
    "    # 取出高置信度的项集组合\n",
    "    def get_conf_high(self,thd,h_thd=10):\n",
    "        return self.apr_blk.getConf(low=False, h_thd=h_thd, l_thd=thd)\n",
    "    # 取出低置信度的项集组合\n",
    "    def get_conf_low(self,thd,hd,l_thd=1):\n",
    "        return self.apr_blk.getConf(h_thd=thd,l_thd=l_thd,hd=hd)\n",
    "\n",
    "\n",
    "def main():\n",
    "    data=[\n",
    "        [\"牛奶\",\"啤酒\",\"尿布\"],\n",
    "        [\"牛奶\",\"啤酒\",\"咖啡\",\"尿布\"],\n",
    "        [\"香肠\",\"牛奶\",\"饼干\"],\n",
    "        [\"尿布\",\"果汁\",\"啤酒\"],\n",
    "        [\"钉子\",\"啤酒\"],\n",
    "        [\"尿布\",\"毛巾\",\"香肠\"],\n",
    "        [\"啤酒\",\"毛巾\",\"尿布\",\"饼干\"]\n",
    "    ]\n",
    "    # 频繁项集\n",
    "    print(\"Freq\",AssctAnaClass().fit(data).get_freq(thd=3,hd=10))\n",
    "    # 置信度\n",
    "    print(\"Conf\",AssctAnaClass().fit(data).get_conf_high(thd=3,h_thd=3))\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
