{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.分类模型评估\n",
    "    # 二分类：标注分类只有两类。正类用1表示（比较关注），负类用0表示\n",
    "        # 混淆矩阵：\n",
    "            # TP(Ture Positive):实际是正类，识别为正类      Y_11\n",
    "            # FN(False Negative):实际是正类，识别为负类（漏）Y_10\n",
    "            # FP(False Positive):实际是负类，识别为正类（错）Y_01\n",
    "            # TN(True Negative):实际是负类，识别为负类      Y_00\n",
    "        # 关键指标\n",
    "            # 正确率：所有被正确分类所占的比例\n",
    "            # 召回率：真实被分为正类的数据/所有真实的正类\n",
    "            # F-score:2*召回率*准确率/召回率+准确率 \n",
    "            # 查准率（Precision）：真的正类/真的正类+假的正类\n",
    "            # 错误接收率（FPR）:有多少负类被划成了正类的比例 FP/(FP+TN)\n",
    "            # 错误拒绝率（FRR）:真实的所有正类中有多少是被错误拒绝的（有多少真实的正类没有被判为正类） FN/(TP+FN)\n",
    "    # 多类   \n",
    "        # 多元混淆矩阵：\n",
    "            # 正确率：所有被正确分类所占的比例\n",
    "            # 召回率 和 F-score\n",
    "                # 1.先计算所有的TP，FN等，再以二值方法计算 (micro方法)\n",
    "                # 2.分别把每个类别当作正类，都算一个召回或者F值，然后取加权（weighted）或者不加权(macro)的平均\n",
    "    # 取阈值：\n",
    "        # 1.ROC曲线：在ROC中横轴代表的是FPR（错误接收率），纵轴代表的是TPR（召回率）。ROC曲线能很容易的查出任意界限值时的对性能的识别力\n",
    "        # 2.AUC：是ROC曲线下的面积，其值可以直观反应ROC曲线向左上方的靠近程度\n",
    "# 2.回归模型评估\n",
    "# 3.聚类模型评估\n",
    "# 4.关联模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X        number_project  average_monthly_hours\n",
      "0                 0.0               0.285047\n",
      "1                 0.6               0.775701\n",
      "2                 1.0               0.822430\n",
      "3                 0.6               0.593458\n",
      "4                 0.0               0.294393\n",
      "...               ...                    ...\n",
      "14994             0.0               0.257009\n",
      "14995             0.0               0.299065\n",
      "14996             0.0               0.219626\n",
      "14997             0.8               0.859813\n",
      "14998             0.0               0.289720\n",
      "\n",
      "[14999 rows x 2 columns]\n",
      "Y 0        0.265625\n",
      "1        0.781250\n",
      "2        0.812500\n",
      "3        0.796875\n",
      "4        0.250000\n",
      "           ...   \n",
      "14994    0.328125\n",
      "14995    0.187500\n",
      "14996    0.265625\n",
      "14997    0.937500\n",
      "14998    0.250000\n",
      "Name: last_evaluation, Length: 14999, dtype: float64\n",
      "Coef: [0.22810785 0.21537058]\n",
      "MSE: 0.05993150070504495\n",
      "MAE: 0.20767975383640475\n",
      "R2: 0.16209792042024462\n"
     ]
    }
   ],
   "source": [
    "# 回归测试\n",
    "def regr_test(features, label):\n",
    "    print(\"X\", features)\n",
    "    print(\"Y\", label)\n",
    "    # LinearRegression 线性回归\n",
    "    # Ridge 岭回归\n",
    "    # Lasso\n",
    "    from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "    # 线性回归 (常用)\n",
    "    # regr = LinearRegression()\n",
    "    # 岭回归 （特殊情况使用）\n",
    "    # regr = Ridge(alpha=0.8)\n",
    "    # Lasso （特殊情况使用）\n",
    "    regr = Lasso(alpha=0.004)\n",
    "    \n",
    "    regr.fit(features.values, label.values)\n",
    "    # 预测\n",
    "    Y_pred = regr.predict(features.values)\n",
    "    # 参数\n",
    "    print(\"Coef:\", regr.coef_)\n",
    "    # 衡量回归方程的好坏\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    print(\"MSE:\", mean_squared_error(label.values, Y_pred))\n",
    "    # 回归模型评估\n",
    "    print(\"MAE:\", mean_absolute_error(label.values, Y_pred))\n",
    "    print(\"R2:\", r2_score(label.values, Y_pred))\n",
    "\n",
    "def hr_preprocessing(sl=False, le=False, npr=False, amh=False, tsc=False, wa=False, pl5=False, dp=False, slr=False, lower_d = False, ld_n = 1):\n",
    "    df = pd.read_csv('./data/HR.csv')\n",
    "    # 1.清洗数据\n",
    "    df = df.dropna(subset=['satisfaction_level', 'last_evaluation'])\n",
    "    df = df[df['satisfaction_level']<=1][df['salary']!='nme']\n",
    "    # 2.得到标注\n",
    "    label = df[\"left\"]\n",
    "    df = df.drop('left', axis=1)\n",
    "    # 3.特征选择\n",
    "\n",
    "    # 4.特征处理\n",
    "    scaler_lst = [sl, le, npr, amh, tsc, wa, pl5]\n",
    "    column_lst = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_monthly_hours', 'time_spend_company', 'Work_accident', 'promotion_last_5years']\n",
    "    for i in range(len(scaler_lst)):\n",
    "        if not scaler_lst[i]:\n",
    "            df[column_lst[i]]=MinMaxScaler().fit_transform(df[column_lst[i]].values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "        else:\n",
    "            df[column_lst[i]]=StandardScaler().fit_transform(df[column_lst[i]].values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "    # # 将离散值数值化\n",
    "    scaler_lst = [dp, slr]\n",
    "    column_lst = [\"department\", \"salary\"]\n",
    "    for i in range(len(scaler_lst)):\n",
    "        if not scaler_lst[i]:\n",
    "            if column_lst[i] == \"salary\":\n",
    "                df[column_lst[i]] = [map_salary(s) for s in df['salary'].values]\n",
    "            else:\n",
    "                df[column_lst[i]] = LabelEncoder().fit_transform(df[column_lst[i]])\n",
    "            df[column_lst[i]] = MinMaxScaler().fit_transform(df[column_lst[i]].values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "        else:\n",
    "            # OneHotEncoder\n",
    "            df = pd.get_dummies(df, columns=[column_lst[i]])\n",
    "    # 降维\n",
    "    if lower_d:\n",
    "        # n_components 不能大于类的个数\n",
    "        # return LinearDiscriminantAnalysis(n_components=ld_n)\n",
    "        # PCA n_components 不受限制\n",
    "        return PCA(n_components=ld_n).fit_transform(df.values)  \n",
    "    return df, label\n",
    "\n",
    "d = dict([('low', 0), ('medium', 1), ('high', 2)])\n",
    "def map_salary(s):\n",
    "    return d.get(s, 0)\n",
    "\n",
    "# 训练集 验证集 测试集\n",
    "def hr_modeling(features, label):\n",
    "    # 引入切分训练集和测试集的函数\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    # 先取值\n",
    "    f_v = features.values\n",
    "    l_v = label.values\n",
    "    # test_size 测试集占多少比例  \n",
    "    # X_tt  训练集部分 X_validation标注\n",
    "    # y_tt  验证集部分 Y_validation标注\n",
    "    # 得到验证集\n",
    "    X_tt, X_validation, Y_tt, Y_validation = train_test_split(f_v, l_v, test_size=0.2)\n",
    "    # 区分验证集和测试集\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_tt, Y_tt, test_size=0.25)\n",
    "    # print(len(X_train), len(X_validation), len(X_test))\n",
    "    \n",
    "    # 衡量指标\n",
    "    # accuracy_score 准确率\n",
    "    # recall_score 召回率\n",
    "    # f1_score F值\n",
    "    from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "    # KNN\n",
    "    # NearestNeighbors 此方法可以直接获得一个点附近最近的几个点\n",
    "    from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "    # 逻辑回归\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    # 提升树 GBDT\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    \n",
    "    \n",
    "    # 人工神经网络\n",
    "    # Sequential 层级容器\n",
    "    from keras.models import Sequential\n",
    "    # Dense 神经网络层/稠密层， Activation激活函数\n",
    "    from keras.layers.core import Dense, Activation\n",
    "    # 随机梯度下降算法\n",
    "    from keras.optimizers import SGD \n",
    "    # 反向传播算法 PyBrain\n",
    "    mdl = Sequential()\n",
    "    # 创建稠密层表示输入层\n",
    "    # 50 下个隐含层的神经元个数\n",
    "    # input_dim  输入的维度\n",
    "    mdl.add(Dense(50, input_dim=len(f_v[0])))\n",
    "    # 激活函数\n",
    "    mdl.add(Activation(\"sigmoid\"))\n",
    "    # 接入输出层 (上一层输出几个，下一层就会输入几个)\n",
    "    mdl.add(Dense(2))\n",
    "    # 保证归一化\n",
    "    mdl.add(Activation(\"softmax\"))\n",
    "    # 优化器 lr 学习率\n",
    "    sgd = SGD(lr=0.08)\n",
    "    # 编译建立模型\n",
    "    # loss 最优化函数、损失函数\n",
    "    # mean_squared_error 平均平方误差\n",
    "    # optimizer 使用什么样的优化器  sgd  adam(亚当优化器)，迈开步子跑 \n",
    "    # nb_epoch 一共迭代的次数 \n",
    "    # batch_size 随机梯度下降算法每次选取的数量。\n",
    "    mdl.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "    mdl.fit(X_train, np.array([[0, 1] if i==1 else [1, 0] for i in Y_train]), nb_epoch=1000, batch_size=8999)\n",
    "    # 引入ROC曲线\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "    f = plt.figure()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 进行预测和评价 【训练集，验证集，测试集】\n",
    "    xy_lst = [(X_train, Y_train), (X_validation, Y_validation), (X_test, Y_test)]\n",
    "    for i in range(len(xy_lst)):\n",
    "        # X_part 真实值\n",
    "        X_part = xy_lst[i][0]\n",
    "        # y_part 预测值\n",
    "        Y_part = xy_lst[i][1]\n",
    "        # 预测值\n",
    "        Y_pred = mdl.predict(X_part)\n",
    "        print(Y_pred)\n",
    "        # 取其为正类的概率\n",
    "        Y_pred = np.array(Y_pred[:1]).reshape((1, -1))[0]\n",
    "        # 绘制图形\n",
    "        f.add_subplot(1, 3, i+1)\n",
    "        # 返回值有 fpr tpr  thresholds阈值\n",
    "        fpr, tpr, thresholds = roc_curve(Y_part, Y_pred)\n",
    "        plt.plot(fpr, tpr)\n",
    "        print(\"NN\", \"AUC\", auc(fpr, tpr))\n",
    "        print(\"NN\", \"AUC_Score\", roc_auc_score(Y_part, Y_pred))\n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "#     models = []\n",
    "#     # Adaboost\n",
    "#     # random_state 随机数的种子值\n",
    "#     # base_estimator 弱分类的基本分类器 需要两个属性 classes_ 和 n_classes_ 默认的是决策树\n",
    "#     # n_estimators 及联的决策树的数量 默认是50个\n",
    "#     # learning_rate 根据0-1的数进行衰减\n",
    "#     # algorithm 针对 base_estimator 进行的选择，如果base_estimator可以得到一个判别的概率，那么就可以使用SAMME.R,得到更好的效果\n",
    "# #     models.append((\"AdaBoost\", AdaBoostClassifier(n_estimators=100)))\n",
    "#     # penalty l1,l2 使用L1正则化或L2正则化\n",
    "#     # tol 计算的精度\n",
    "#     # C C越大，正则化因子所占的比例越小，反之越大\n",
    "#     # solver 使用的方法 sag 随机平均梯度下降算法 默认是liblinear\n",
    "#     # max_iter 最大的迭代次数\n",
    "#     # coef_ 参数\n",
    "#     # intercept_ 截距\n",
    "#     models.append((\"LogisticRegression\", LogisticRegression(C=1000, tol=1e-10, solver=\"sag\", max_iter=10000)))\n",
    "#     # 提升树 GBDT\n",
    "#     # max_depth 深度\n",
    "#     # n_estimators 树的数量\n",
    "#     # learning_rate 衰减比率\n",
    "#     # criterion 标准\n",
    "#     models.append((\"GBDT\", GradientBoostingClassifier(max_depth=6, n_estimators=100)))\n",
    "#     for clf_name, clf in models:\n",
    "#         # 先进行拟合 训练\n",
    "#         clf.fit(X_train, Y_train)\n",
    "#         # 进行预测和评价 【训练集，验证集，测试集】\n",
    "#         xy_lst = [(X_train, Y_train), (X_validation, Y_validation), (X_test, Y_test)]\n",
    "#         for i in range(len(xy_lst)):\n",
    "#             # X_part\n",
    "#             X_part = xy_lst[i][0]\n",
    "#             # y_part\n",
    "#             Y_part = xy_lst[i][1]\n",
    "#             # 预测值\n",
    "#             Y_pred = clf.predict(X_part)\n",
    "#             # 0训练集 1验证集 2测试集\n",
    "#             print(i)\n",
    "#             print(clf_name, \"-ACC:\", accuracy_score(Y_part,  Y_pred))\n",
    "#             print(clf_name, \"-REC:\", recall_score(Y_part,  Y_pred))\n",
    "#             print(clf_name, \"-F-Score:\", f1_score(Y_part,  Y_pred))\n",
    "            \n",
    "def main():\n",
    "    # print(hr_preprocessing(lower_d = False, ld_n = 3))\n",
    "    features, label = hr_preprocessing()\n",
    "    regr_test(features[[\"number_project\", \"average_monthly_hours\"]], features[\"last_evaluation\"])\n",
    "    \n",
    "#     hr_modeling(features, label)\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增益率与KS图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增益图：横轴是测试图的取样比例，纵轴是平均样本比例/平均比例 例子：作弊用户\n",
    "# KS图：横轴为测试集取样比例，纵轴为TPR和FPR。关注的是两条曲线的最大差距。这个差距可以反映对正类样本的区分度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回归模型要拟合的真实值是连续值，所以回归模型的预测值也是连续值。我们的任务就是确定这两个连续值序列的差距到底有多大\n",
    "# 常用的方法：\n",
    "    # 关键指标\n",
    "    # MAE(Mean Absolute Error):每个预测值与真实值相减(残差)，取绝对值相加，最后求平均。（不常用）\n",
    "    # MSE（Mean Square Error）:每个预测值与真实值相减(残差)的平方相加，最后求平均。（常用）\n",
    "    # RMSE(Root MSE):对MSE求开根号\n",
    "    # r2_score(决定系数)：SSR/SST=预测值相对与真实平均值的离散程度/真实值的离散程度\n",
    "# 代码看上面"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 聚类模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关键指标：\n",
    "    # RMS(Root Mean Square):每个聚类的值-每个类的平均值平方再求和，再对和开根号在求均值。值越小聚类效果越好\n",
    "    # 轮廓系数\n",
    "        # a(i)为样本i与簇内其他样本的平均距离；\n",
    "        # b(i)为样本i与其他某簇样本的平均距离，多个簇b(i)取最小\n",
    "        # s(i) = b(i)-a(i)/max{a(i), b(i)}   分离度-内聚度/分离度或内聚度中较大的那一个  分离度越大越好，内聚度越小越好。\n",
    "        # s(i)越趋近于1越好，越接近于-1越糟糕\n",
    "# 代码看-- 6_数据挖掘建模_04_聚类 --中的代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关联模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关键指标  可参考 6_数据挖掘建模_04_聚类\n",
    "    # 支持度：可以帮助我们找到最大的频繁项集，它可形成一种规模效应，可以形成多种组合\n",
    "    # 置信度：观察组合之间的关系，可以得到置信度\n",
    "    # 提升度：看置信度对另外一个项集是否有提升作用"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
