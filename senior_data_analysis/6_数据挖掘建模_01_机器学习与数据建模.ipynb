{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学习：通过接收到的数据，归纳提取相同与不同。\n",
    "# 机器学习：让计算机以数据为基础，进行归纳与总结\n",
    "# 模型：数据解释现象的系统\n",
    "# 机器学习：\n",
    "    # 监督学习（有标注）\n",
    "        # 分类：标注是离散值\n",
    "        # 回归：标注是连续值\n",
    "    # 非监督学习（无标注）完全让数据自己说话，将数据不同的特征在不同的模型中进行不同的表现\n",
    "        # 聚类分析\n",
    "        # 关联分析\n",
    "    # 半监督学习（部分有标注部分无标注）有标注的数据可以作用与无标注的数据，反过来也可以"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一份数据集可分为：(所占的比例为6:2:2)\n",
    "# 1.训练集 (6)：用来训练和拟合模型\n",
    "# 2.验证集 (2)：当通过训练集训练出多个模型后，使用验证集数据纠偏或比较预测\n",
    "# 3.测试集 (2)：模型泛化能力的考量。\n",
    "    # 泛化：对未知数据的预测能力\n",
    "# 如果没有验证集，则训练集和测试集的比例为4:1\n",
    "# K-fold交叉验证：将数据集分成K份，每份轮流做一遍测试集，其它做训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999 3000 3000\n"
     ]
    }
   ],
   "source": [
    "# 归一化将数据转化到 0-1 之间的范围\n",
    "# sl:satisfaction_level\n",
    "# le:last_evaluation\n",
    "# npr:number_project\n",
    "# amh:average_monthly_hours\n",
    "# tsc:time_spend_company\n",
    "# wa:Work_accident\n",
    "# pl5:promotion_last_5years\n",
    "# False:MinMaxScaler\n",
    "# True:StandardScaler\n",
    "# 将离散值数值化\n",
    "# dp:department \n",
    "# slr:salary\n",
    "# False:LabelEncoding\n",
    "# True:OneHotEncoder\n",
    "# 降维\n",
    "# lower_d = False  不降维\n",
    "# ld_n = 1 下降的维度\n",
    "def hr_preprocessing(sl=False, le=False, npr=False, amh=False, tsc=False, wa=False, pl5=False, dp=False, slr=False, lower_d = False, ld_n = 1):\n",
    "    df = pd.read_csv('./data/HR.csv')\n",
    "    # 1.清洗数据\n",
    "    df = df.dropna(subset=['satisfaction_level', 'last_evaluation'])\n",
    "    df = df[df['satisfaction_level']<=1][df['salary']!='nme']\n",
    "    # 2.得到标注\n",
    "    label = df[\"left\"]\n",
    "    df = df.drop('left', axis=1)\n",
    "    # 3.特征选择\n",
    "    \n",
    "    # 4.特征处理\n",
    "    scaler_lst = [sl, le, npr, amh, tsc, wa, pl5]\n",
    "    column_lst = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_monthly_hours', 'time_spend_company', 'Work_accident', 'promotion_last_5years']\n",
    "    for i in range(len(scaler_lst)):\n",
    "        if not scaler_lst[i]:\n",
    "            df[column_lst[i]]=MinMaxScaler().fit_transform(df[column_lst[i]].values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "        else:\n",
    "            df[column_lst[i]]=StandardScaler().fit_transform(df[column_lst[i]].values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "    # # 将离散值数值化\n",
    "    scaler_lst = [dp, slr]\n",
    "    column_lst = [\"department\", \"salary\"]\n",
    "    for i in range(len(scaler_lst)):\n",
    "        if not scaler_lst[i]:\n",
    "            if column_lst[i] == \"salary\":\n",
    "                df[column_lst[i]] = [map_salary(s) for s in df['salary'].values]\n",
    "            else:\n",
    "                df[column_lst[i]] = LabelEncoder().fit_transform(df[column_lst[i]])\n",
    "            df[column_lst[i]] = MinMaxScaler().fit_transform(df[column_lst[i]].values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "        else:\n",
    "            # OneHotEncoder\n",
    "            df = pd.get_dummies(df, columns=[column_lst[i]])\n",
    "    \n",
    "    # 降维\n",
    "    if lower_d:\n",
    "        # n_components 不能大于类的个数\n",
    "        # return LinearDiscriminantAnalysis(n_components=ld_n)\n",
    "        \n",
    "        # PCA n_components 不受限制\n",
    "        return PCA(n_components=ld_n).fit_transform(df.values)\n",
    "        \n",
    "    \n",
    "    return df, label\n",
    "\n",
    "d = dict([('low', 0), ('medium', 1), ('high', 2)])\n",
    "def map_salary(s):\n",
    "    return d.get(s, 0)\n",
    "\n",
    "# 训练集 验证集 测试集\n",
    "def hr_modeling(features, label):\n",
    "    # 引入切分训练集和测试集的函数\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    # 先取值\n",
    "    f_v = features.values\n",
    "    l_v = label.values\n",
    "    # test_size 测试集占多少比例  \n",
    "    # X_tt  训练集部分 X_validation标注\n",
    "    # y_tt  验证集部分 Y_validation标注\n",
    "    # 得到验证集\n",
    "    X_tt, X_validation, Y_tt, Y_validation = train_test_split(f_v, l_v, test_size=0.2)\n",
    "    # 区分验证集和测试集\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_tt, Y_tt, test_size=0.25)\n",
    "    print(len(X_train), len(X_validation), len(X_test))\n",
    "    \n",
    "def main():\n",
    "    # print(hr_preprocessing(lower_d = False, ld_n = 3))\n",
    "    features, label = hr_preprocessing()\n",
    "    hr_modeling(features, label)\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
