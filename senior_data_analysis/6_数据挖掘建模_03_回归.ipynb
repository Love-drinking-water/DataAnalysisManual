{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线性回归\n",
    "## 决策树回归\n",
    "## 支持向量机回归\n",
    "## 集成方法回归\n",
    "# 罗吉斯特映射回归\n",
    "# 人工神经网络回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回归分析是确定多个变量间相互依赖的定量关系的一种统计分析方法。\n",
    "# 如果多个变量间的关系用线性关系去考量，那就是线性回归。如果用多项式关系去考量，那就是多项式回归。\n",
    "# 最小二乘法\n",
    "# 核心的算法：是一个最优化的过程，是求一个函数最小值的过程，而且也可以证明这个函数是连续可导的。方法：对函数的未知数进行求导，求各个极值，如果值域不是负无穷，那么极小值中一定会有一个最小的。\n",
    "# 梯度下降法：求最小值，节省计算机资源开销。导数：标量（也就是斜率的大小）  梯度：矢量（指定了各个方向上的导数的大小，同时梯度要求函数具有一阶偏导，也是说对每个参数的分量都要可导），梯度指的方向是一个点最大的上升方向。\n",
    "# 线性回归的进化（正则化）。选择系数更小的，可以有效的防止过拟合，也可以更快速的找到最优点\n",
    "    # 岭回归：用到的是L2正则化\n",
    "    # Lasso回归："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X        number_project  average_monthly_hours\n",
      "0                 0.0               0.285047\n",
      "1                 0.6               0.775701\n",
      "2                 1.0               0.822430\n",
      "3                 0.6               0.593458\n",
      "4                 0.0               0.294393\n",
      "...               ...                    ...\n",
      "14994             0.0               0.257009\n",
      "14995             0.0               0.299065\n",
      "14996             0.0               0.219626\n",
      "14997             0.8               0.859813\n",
      "14998             0.0               0.289720\n",
      "\n",
      "[14999 rows x 2 columns]\n",
      "Y 0        0.265625\n",
      "1        0.781250\n",
      "2        0.812500\n",
      "3        0.796875\n",
      "4        0.250000\n",
      "           ...   \n",
      "14994    0.328125\n",
      "14995    0.187500\n",
      "14996    0.265625\n",
      "14997    0.937500\n",
      "14998    0.250000\n",
      "Name: last_evaluation, Length: 14999, dtype: float64\n",
      "Coef: [0.22810785 0.21537058]\n",
      "MSE: 0.05993150070504495\n"
     ]
    }
   ],
   "source": [
    "# 回归测试\n",
    "def regr_test(features, label):\n",
    "    print(\"X\", features)\n",
    "    print(\"Y\", label)\n",
    "    # LinearRegression 线性回归\n",
    "    # Ridge 岭回归\n",
    "    # Lasso\n",
    "    from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "    # 线性回归 (常用)\n",
    "    # regr = LinearRegression()\n",
    "    # 岭回归 （特殊情况使用）\n",
    "    # regr = Ridge(alpha=0.8)\n",
    "    # Lasso （特殊情况使用）\n",
    "    regr = Lasso(alpha=0.004)\n",
    "    \n",
    "    regr.fit(features.values, label.values)\n",
    "    # 预测\n",
    "    Y_pred = regr.predict(features.values)\n",
    "    # 参数\n",
    "    print(\"Coef:\", regr.coef_)\n",
    "    # 衡量回归方程的好坏\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    print(\"MSE:\", mean_squared_error(Y_pred, label.values))\n",
    "\n",
    "def hr_preprocessing(sl=False, le=False, npr=False, amh=False, tsc=False, wa=False, pl5=False, dp=False, slr=False, lower_d = False, ld_n = 1):\n",
    "    df = pd.read_csv('./data/HR.csv')\n",
    "    # 1.清洗数据\n",
    "    df = df.dropna(subset=['satisfaction_level', 'last_evaluation'])\n",
    "    df = df[df['satisfaction_level']<=1][df['salary']!='nme']\n",
    "    # 2.得到标注\n",
    "    label = df[\"left\"]\n",
    "    df = df.drop('left', axis=1)\n",
    "    # 3.特征选择\n",
    "\n",
    "    # 4.特征处理\n",
    "    scaler_lst = [sl, le, npr, amh, tsc, wa, pl5]\n",
    "    column_lst = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_monthly_hours', 'time_spend_company', 'Work_accident', 'promotion_last_5years']\n",
    "    for i in range(len(scaler_lst)):\n",
    "        if not scaler_lst[i]:\n",
    "            df[column_lst[i]]=MinMaxScaler().fit_transform(df[column_lst[i]].values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "        else:\n",
    "            df[column_lst[i]]=StandardScaler().fit_transform(df[column_lst[i]].values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "    # # 将离散值数值化\n",
    "    scaler_lst = [dp, slr]\n",
    "    column_lst = [\"department\", \"salary\"]\n",
    "    for i in range(len(scaler_lst)):\n",
    "        if not scaler_lst[i]:\n",
    "            if column_lst[i] == \"salary\":\n",
    "                df[column_lst[i]] = [map_salary(s) for s in df['salary'].values]\n",
    "            else:\n",
    "                df[column_lst[i]] = LabelEncoder().fit_transform(df[column_lst[i]])\n",
    "            df[column_lst[i]] = MinMaxScaler().fit_transform(df[column_lst[i]].values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "        else:\n",
    "            # OneHotEncoder\n",
    "            df = pd.get_dummies(df, columns=[column_lst[i]])\n",
    "    # 降维\n",
    "    if lower_d:\n",
    "        # n_components 不能大于类的个数\n",
    "        # return LinearDiscriminantAnalysis(n_components=ld_n)\n",
    "        # PCA n_components 不受限制\n",
    "        return PCA(n_components=ld_n).fit_transform(df.values)  \n",
    "    return df, label\n",
    "\n",
    "d = dict([('low', 0), ('medium', 1), ('high', 2)])\n",
    "def map_salary(s):\n",
    "    return d.get(s, 0)\n",
    "\n",
    "def main():\n",
    "    # print(hr_preprocessing(lower_d = False, ld_n = 3))\n",
    "    features, label = hr_preprocessing()\n",
    "    regr_test(features[[\"number_project\", \"average_monthly_hours\"]], features[\"last_evaluation\"])\n",
    "    \n",
    "    # hr_modeling(features, label)\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
